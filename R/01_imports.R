#' @title Import clustering results generated by SPADE
#'
#' @description 
#' The 'importSPADEResults()' function imports SPADE cell clustering results from a specified path.
#' This function returns a 'SPADEResult' object.
#' 
#' This function import the expression matrix and count matrix as well as the SPADE tree.
#' This function apply an hyperbolic sine transformation to imported FCS data and compute the maker range quantiles.
#' 
#' @details
#' The computation of maker range quantiles can be approximated using quantile.heuristic parameter which is more efficient in term of loading time and memory usage.
#'  
#' @param path a character specify the path of SPADE results folder
#' @param dict a two column dataframe providing the correspondance between the original marker names (first column) and the real marker names (second column)
#' @param exclude.markers a character vector of markers to exclude (case insentive)
#' @param probs a vector of probabilities with 2 values in [0,1] to compute maker range quantiles. First is the lower bound and second is the upper bound.
#' @param use.raw.medians a logicial specifying if "transformed" or "raw" medians will be use in the cluster expression matrix (FALSE by default)
#' @param quantile.heuristic a logicial specifying if maker range quantiles are computed using all cells (FALSE), or is the means of the quantile of each samples (TRUE)
#' 
#' @return a S4 object of class 'SPADEResults'
#'
#' @import flowCore 
#'
#' @export 
importSPADEResults <- function(path,
                               dict               = data.frame(),
                               exclude.markers    = c("cell_length", "FileNum", "density", "time"),
                               probs              = c(0.05,0.95),
                               use.raw.medians    = FALSE,
                               quantile.heuristic = FALSE){
    
    message("[START] - extracting SPADE results")
    message(paste0(basename(path),"\n"))
    path <- normalizePath(path,"/")
    
    message("FCS files import:")
    fcs.files         <- dir(path, full.names = TRUE, pattern = ".fcs.density.fcs.cluster.fcs$")
    samples.names     <- gsub(".fcs.density.fcs.cluster.fcs", "", basename(fcs.files))
    fcs.files         <- dir(path, full.names = TRUE, pattern = ".fcs.density.fcs.cluster.fcs$")
    flowset           <- flowCore::read.flowSet(fcs.files, emptyValue = TRUE)
    flowCore::sampleNames(flowset) <- samples.names

    if(nrow(dict)>0){
        flowset@colnames <- rename.markers(flowset@colnames, dict)
        flowset    <- flowset[,1:length(flowset@colnames)]
    }
    
    if (!is.null(exclude.markers)){
        flowset <- exclude.markers(flowset, exclude.markers, colnames.FCS = flowset@colnames)
    }
    message("\tarchsin transform...")
    
    transform.arcsinh <- flowCore::arcsinhTransform(a=0, b=0.2) #a and b match SPADE a and b
    marker.toTransform <- setdiff(flowset@colnames, c("cluster"))
    transformations <- flowCore::transformList(marker.toTransform, transform.arcsinh)
    flowset <- flowCore::transform(flowset, transformations)

    message("\tcompute quantiles...")
    
    if(quantile.heuristic){
        quantiles <- computeQuantile.heuristic(flowset,probs)
    }
    else{
        quantiles <- computeQuantile(flowset,probs)
    }
    gc()    
    message("\treading SPADE results...")

    files <- dir(paste(path,"/tables/bySample/",sep=""),full.names = TRUE)
    
    path.clusters.table   <- paste(path,"clusters.table",sep = "/")
    header.clusters.table <- readLines(path.clusters.table,n = 1)
    header.clusters.table <- gsub("\\\"","",header.clusters.table)
    cluster               <- unlist(strsplit(header.clusters.table," "))
    
    marker.expressions <- data.frame(stringsAsFactors = FALSE)
    cells.count        <- data.frame()
    cells.percent      <- data.frame()

    for(file in files){
        
        SPADES.matrix        <- read.table(file,sep = ",",header = TRUE,stringsAsFactors = FALSE,check.names = FALSE)
        
        cells.count.sample   <- SPADES.matrix [,"count"]
        
        name <- gsub('.fcs.density.fcs.cluster.fcs.anno.Rsave_table.csv$','',basename(file))
        
        if(nrow(cells.count)){
            cells.count     <- cbind(cells.count, cells.count.sample)
            samples.headers <- append(samples.headers,name)
        }else{
            cells.count     <- data.frame(row.names = SPADES.matrix [,"ID"], cells.count.sample)
            samples.headers <- name
        }
        
        SPADES.matrix <- SPADES.matrix[, grep ("count|percenttotal",colnames(SPADES.matrix), invert = TRUE)]
        
        SPADES.matrix      <- cbind(name = rep(name,nrow(SPADES.matrix)),SPADES.matrix)
        marker.expressions <- rbind(marker.expressions,SPADES.matrix)

    }
    
    nb.cluster <- nrow(cells.count)
    colnames(cells.count)   <- samples.headers

    marker.expressions.header <- colnames(marker.expressions)
    marker.expressions.header <- gsub("X.","(",marker.expressions.header,fixed = TRUE)
    marker.expressions.header <- gsub(".",")",marker.expressions.header,fixed = TRUE)
    marker.expressions.header[1] <- "sample"
    marker.expressions.header[2] <- "cluster"
    colnames(marker.expressions) <- marker.expressions.header
    
    marker.expressions <- filter.medians(marker.expressions,use.raw.medians)
    
    marker.expressions.header  <- colnames(marker.expressions)
    clustering.markers.indices <- grep("_clust",marker.expressions.header)
    marker.expressions.header  <- gsub("_clust","",marker.expressions.header)

    if(nrow(dict)>0){           
        colnames(marker.expressions)  <- rename.markers(marker.expressions.header,dict)    
    }else{
        colnames(marker.expressions)  <- marker.expressions.header
    }
    
    clustering.markers <- colnames(marker.expressions)[clustering.markers.indices]
    
    if(!is.null(exclude.markers)){
        marker.expressions <- exclude.markers(marker.expressions,exclude.markers)
        clustering.markers <- setdiff(clustering.markers,exclude.markers)
    }

    graph        <- igraph::read.graph(paste(path,"./mst.gml",sep = ""),format = "gml")
    graph.layout <- as.matrix(read.table(paste0(path,"/layout.table"),sep = " ",quote = "",stringsAsFactors = FALSE))

    markers.names <- colnames(marker.expressions[, grep ("cluster|sample",colnames(marker.expressions), invert = TRUE)])
    
    res <- new("SPADEResults", 
               marker.expressions  = marker.expressions,
               use.raw.medians     = use.raw.medians,
               dictionary          = dict,
               cells.count         = cells.count,
               sample.names        = samples.names,
               marker.names        = markers.names,
               marker.clustering   = markers.names %in% clustering.markers,
               cluster.number      = nrow(cells.count),
               flowset             = flowset,
               fcs.files           = fcs.files,
               quantiles           = quantiles,
               graph.layout        = graph.layout,
               graph               = graph)
    
    message("[END] - extracting SPADE results")
    
    return(res)
    
}

#' @title Import clustering results generated by other algorithms
#'
#' @description
#' The 'importX()' function imports cell clustering results from two dataframes ('cells.count' and 'marker.expressions').
#' This function returns a 'Result' object.
#' 
#' @details
#' The detailled format of 'cells.count' dataframe must be formated as following:
#' 
#' \tabular{ccc}{
#'    cluster \tab sample1 \tab sample1\cr
#'    cluster1 \tab 749 \tab 5421\cr
#'    cluster2 \tab 450 \tab 412\cr
#' }
#' 
#' The detailled format of 'marker.expressions' dataframe must be formated as following:
#' 
#' \tabular{cccc}{
#'    sample \tab cluster \tab marker1 \tab marker2\cr
#'    sample1 \tab cluster1 \tab 0.2 \tab 0.3\cr
#'    sample1 \tab cluster2 \tab 0.1 \tab 0.3\cr
#'    sample2 \tab cluster1 \tab 0.5 \tab 2.3\cr
#'    sample2 \tab cluster2 \tab 1   \tab 1.3\cr
#' }
#' 
#' @param cells.count a dataframe of cells abondances with clusters in row and samples in column 
#' @param marker.expressions a dataframe containing median marker expression values for each cluster of each sample. In additions of markers, the 2 two first columns are are dedicated to "cluster" and "sample" 
#' 
#' @return a S4 object of class 'Results'
#' 
#' @export 
importResults <- function(cells.count,
                          marker.expressions){
                      
    colnames(marker.expressions)[1] <- "sample"                 
    colnames(marker.expressions)[2] <- "cluster"
    
    colnames(cells.count)[1]        <- "cluster"
    
    res <- new("Results", 
               marker.expressions  = marker.expressions,
               cells.count         = cells.count,
               sample.names        = as.character(setdiff(unique(results@marker.expressions$sample),"cluster")),
               marker.names        = colnames(marker.expressions)[3:length(marker.expressions)],
               cluster.number      = length(unique(marker.expressions$cluster)))    
}

#' @title Internal - Renaming cell markers
#' 
#' @description 
#' This function is used internally to rename the cell markers based on a dictionary.
#'
#' @details 
#' Dictionary is a data.frame used to rename the marker names. The first column must correspond to the original marker names, the second column must correspond to the new marker names. 
#'
#' @param header a character vector containing the original maker names
#' @param dictionary a character vector containing a correspondence between the original and the new marker names
#' 
#' @return a character vector containing the renamed marker names
rename.markers <- function(header,dictionary){
      
    dictionary[,1] <- as.vector(dictionary[,1])
    dictionary[,2] <- as.vector(dictionary[,2])
    
    if(length(unique(dictionary[,1]))!=length(dictionary[,1])){
        stop("Duplicate in dictionary 'original marker names'")
    }
    if(length(unique(dictionary[,2]))!=length(dictionary[,2])){
        stop("Duplicate in dictionary 'new marker names'")
    }
    header.old <- header
    for(i in 1:nrow(dictionary)){
        header[which(header==dictionary[i,1])[1]] <- dictionary[i,2]
    }
    
    return(header)
}


#' @title Internal - Removing of cell markers to exclude from a matrix
#'
#' @description 
#' This function is used internally to remove one or several cell markers.
#' 
#' @details 
#' If the data parameter is a dataframe the colnames.FCS parameter is ignored but if the data parameter is a flowset, the colnames.FCS parameter is required.
#' 
#' @param data a numeric matrix or flowset
#' @param exclude a character vector containing the cell markers to be excluded (case insentive)
#' @param colnames.FCS a character vector containing colnames if data is a FCS flowset
#' 
#' @return a numeric matrix without the cell markers to exclude
exclude.markers <- function(data,exclude, colnames.FCS = NULL){
    
    if(!is.null(colnames.FCS)){
        column <- colnames.FCS
    }else{
        column <- colnames(data) 
    }

    exclude.flags <- toupper(exclude) %in% toupper(column)
    
    if(any(!(exclude.flags))){
       warning(paste0("Unknown marker to exclude: ",paste(exclude[!exclude.flags],collapse=", ")))
    }

    data    <- data[ , -which(toupper(column) %in% toupper(exclude))]

	return(data)
}

#' @title Internal - filter medians to exclude from a matrix
#'
#' @description 
#' This function is used internally to remove raw or transform medians from SPADE matrix. CVS medians are always removed.
#' 
#' @param data a SPADE matrix
#' @param use.raw.medians a logicial specifying if "transformed" or "raw" medians will be use (FALSE by default)
#' 
#' @return a numeric matrix without the cell markers to exclude
filter.medians <- function(data,use.raw.medians = FALSE){

    if(use.raw.medians){
        exclude <- "^medians|^cvs"
    }else{
        exclude <- "^raw_medians|^cvs"
    }
    
    data           <- data[,grep(exclude, colnames(data), invert=TRUE, ignore.case = TRUE)]
    colnames(data) <- gsub("^medians|^cvs|^raw_medians", "", colnames(data))
    
    return(data)
    
}

#' @title Internal - Compute quantile with FCS flowset marker by marker 
#'
#' @description 
#' This function is used internally to compute the maker range quantiles.
#' 
#' @details 
#' This function performs the exact calculation of quantiles with all cells but needs more memory than computeQuantile.heuristic.
#' 
#' @param flowset a flowCore flowset
#' @param probs a numeric vector of 2 values specifying the quantiles to compute
#' 
#' @return a numeric matrix containing the quantiles of each marker
#' 
#' @import flowCore
computeQuantile <- function(flowset,probs = c(0.05,0.95)){

    bounds <- data.frame ()
    markers <- flowset@colnames
    markers <- setdiff(markers,"cluster")
    
    for(marker in markers){
        temp <- c()
        for (j in 1:length(flowset)){    
            frame <- flowset[[j]]@exprs
            temp <- c(temp, frame[,marker])
        }
        if(nrow(bounds) > 0){
            bounds     <- cbind(bounds, t(t(quantile(temp, probs = probs))))# WARNING 
        }else{
            bounds     <- as.data.frame(t(t(quantile(temp, probs = probs))))# WARNING 
        }
    }

    colnames(bounds) <- markers
    rownames(bounds) <- probs
    
    return(bounds)
}

#' @title Internal - Compute quantile with FCS flowset sample by sample
#'
#' @description 
#' This function is used internally to provide the mean of quantiles from each sample to seed up computation.
#' 
#' @details 
#' This function performs an approximate calculation of quantiles using less memory than computeQuantile.
#' 
#' @param flowset a flowCore flowset 
#' @param probs a numeric vector of 2 values specifying the quantiles to compute
#' 
#' @import flowCore
#' 
#' @return a numeric matrix containing the quantiles of each marker
computeQuantile.approximation <- function(flowset,probs = c(0.05,0.95)){
    
    bounds.by.sample <- flowCore::fsApply(flowset[,flowset@colnames != "cluster"], flowCore::each_col, stats::quantile, probs = probs)

    lower.bounds <- bounds.by.sample[seq(from = 1,to = nrow(bounds.by.sample), by = 2),]
    upper.bounds <- bounds.by.sample[seq(from = 2,to = nrow(bounds.by.sample), by = 2),]
    
    lower.bounds <- apply (lower.bounds,2,mean)
    upper.bounds <- apply (upper.bounds,2,mean)
    
    bounds <- rbind(lower.bounds,upper.bounds)
    
    rownames(bounds) <- probs
    
    return (as.data.frame(bounds))
    
}
